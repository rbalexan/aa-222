\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{svg}

\usepackage{booktabs} %@{}
\usepackage{pgfplots}
\pgfplotsset{compat=1.16}
\usepackage[per-mode=symbol,detect-all]{siunitx}
\usepackage{hyperref}
\usepackage{cleveref} %\Cref{} vs. \cref{}
\usepackage[protrusion=true,expansion=true]{microtype}
\usepackage{mathabx} % for \bigtimes


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}


\title{\LARGE \textbf{Constrained Global Optimization Using \\ Exterior and Interior Methods} 
}


\author{\IEEEauthorblockN{  Ross B. Alexander}
\IEEEauthorblockA{\textit{  Department of Aeronautics and Astronautics} \\
\textit{                    Stanford University} \\
                            Stanford, CA 94305 \\
                            rbalexan@stanford.edu}} % or ORCID


\maketitle

\section{Constrained Optimization}

For each of the problems, we use an exterior method coupled with an interior method. 
Decomposing the problem into an exterior method, which searches the design space for a solution in the feasible space, and an interior method, which searches the feasible space, makes use of the strengths of each method while guaranteeing a feasible solution so long as the exterior method converges. 

From our initial design point, we iterate using the exterior method and terminate once a feasible solution is found. The solution from the exterior method is then used as the initial design point for the interior method, which runs until the number of function, gradient, and constraint evaluations reaches the maximum number of allowed evaluations.

\subsection{Exterior Method}

For the exterior method, we use the quadratic penalty method with a forward finite-difference penalty gradient approximation on top of gradient descent with Nesterov momentum.

While zero-order methods can be useful in situations where the gradient of the objective function is not available, first-order methods can improve the search performance in situations where this information is available (as is the case for us). Additionally, in constrained optimization, gradient information can be useful in guiding the search toward feasibility. As a result, we use a penalty method with a quadratic penalty, which introduces a component of objective function proportional to the square of the distance from the nearest constraint boundary, and accordingly, a component of the gradient proportional to twice the distance to the nearest constraint boundary. This additional component of the gradient is an improvement over a count penalty, which only introduces a discontinuity at constraint boundaries and does not help guide the search toward feasibility but rather "corral" the solution to remain in the feasible space. As such, a mixed penalty consisting of a linear combination of a count penalty and a quadratic penalty does not confer much of an advantage over a quadratic penalty alone.\footnote{While the count, quadratic, and mixed penalties are all implemented, we settled on the quadratic penalty.}

As mentioned earlier, we use gradient descent with Nesterov momentum to descend the penalized objective function. Gradient descent with Nesterov momentum exploits the benefits of traditional momentum but employs a look-ahead gradient to reduce momentum near minima, which makes for more efficient gradient descent. Since we are using a first-order method on the penalized objective function to descend into the feasible space, we need to explicitly compute the gradient of the penalty function. For this, we choose a forward finite-difference approximation. While the linear convergence ($\mathcal{O}(h)$) of the forward-difference approximation is clearly inferior to the quadratic convergence ($\mathcal{O}(h^2)$) of the central-difference approximation, we use the forward-difference approximation since after evaluating the penalty at the current design point, we only need to compute its variation at the forward step along each dimension ($n$ function evaluations) versus needing to compute the variations at both the forward and backward step along each dimension ($2n$ function evaluations). While this is a trade-off, we choose the first-order method since the gradient of the penalty function does not need to be known with high precision.

\subsection{Interior Method}

For the interior method, we use the inverse-barrier interior point method on top of the Hooke-Jeeves method.

The interior point method utilizes a similar approach to the penalty method by penalizing near-constraint violation using a barrier penalty function. This barrier function adds a penalty that approaches infinity as the design point approaches the constraint. At each iteration, the strength of the barrier function is decreased by a constant factor, which allows the solution to remain in the feasible space while slowly and safely approaching the constraint boundary using the inner descent method. The process of gradually reducing a penalty applied by the barrier function is similar to simulated annealing, which can help the optimization process avoid local minima. There are two popular choices for barrier functions: an inverse barrier function applies a penalty globally (over the entire feasible space) and a logarithmic barrier function applies a penalty locally (only very close to the constraint boundary), however, to utilize the benefits of simulated annealing, we choose the inverse barrier function over the log barrier function due to the globality of the applied penalty.\footnote{Similarly to the penalty method, while the inverse and log barrier functions are all implemented, we settled on the inverse barrier function.}

We used the Hooke-Jeeves method to descend the penalized objective function in the feasible space. While we have gradient information, which enables us to use first-order methods, we use a first-order method, namely, the Hooke-Jeeves method, to descend the penalized objective function since it is relatively simple to implement. Unfortunately, the Hooke-Jeeves method is the most expensive among pattern-based zero-order methods, requiring $2n$ evaluations per iteration, compared with $n+1$ evaluations per iteration for methods like generalized pattern search (GPS), the Nelder-Mead simplex method, and mesh-adaptive direct search (MADS). This is something we will have to live with. The Hooke-Jeeves method searches along each positive and negative basis for an improvement and accepts the best one -- this behavior can lead the search to get stuck in local minima (as we see in the \texttt{simple2} example, or maybe there is a bug in our implementation).

% For each of the five problems given, describe:

% The algorithm you chose to solve it.
% How you decided which hyperparameters to choose.
% Why you think it works.
% At least one pro and one con to the chosen algorithm.
% Comparison of algorithms

\subsection{Results \& Discussion}

%You must compare the performance of at least two algorithms by doing the following.

%For simple1 and simple2, plot the feasible region (where  c(x)â‰¤0 ) on top of a contour plot of  f(x) . Show the path taken by the algorithm for at least three initial conditions on this plot. Make a separate plot for at least two distinct algorithms (four plots). For both problems the axis limits should be (-3, 3).
%For only simple2, and for at least two distinct algorithms, plot the objective function versus iteration, and maximum constraint violation versus iteration, for at least three initial conditions. Plot the curves for different initial conditions on the same plot, but make a separate plot for the objective and constraint violation, and for each of the two algorithms compared (four plots).

\begin{figure*}[t]
    \centering
    \includesvg[width=0.49\linewidth]{../plots/simple1_alg1.svg}
    \includesvg[width=0.49\linewidth]{../plots/simple2_alg1.svg}
    \caption{Three constrained optimization paths on the \texttt{simple1} function (\textit{left}) and the \texttt{simple2} function (\textit{right}). The feasible space for \texttt{simple1} is the semi-elliptic region in the center and the feasible space for \texttt{simple2} is the left-half region. For the exterior method, these optimizations use the quadratic penalty method ($\rho=1$, $\gamma=2$) with gradient descent with Nesterov momentum ($\alpha=1\textsc{E}-3$, $\beta=0.9$) and for the interior method, these optimizations use the inverse-barrier interior point method ($\rho=1$, $\gamma=2$) on top of the Hooke-Jeeves method ($\alpha_0=1\textsc{E}-1$, $\gamma=0.5$, $\epsilon=1\textsc{E}-4$, $k_{max}=10$). The color gradations for \texttt{simple2} are the base-10 logarithm of the function values.}
    \label{fig:simple1_alg1}
\end{figure*}

\begin{figure*}[h]
    \centering
    \includesvg[width=0.49\linewidth]{../plots/simple1_alg2.svg}
    \includesvg[width=0.49\linewidth]{../plots/simple2_alg2.svg}
    \caption{Three constrained optimization paths on the \texttt{simple1} function (\textit{left}) and the \texttt{simple2} function (\textit{right}). The feasible space for \texttt{simple1} is the semi-elliptic region in the center and the feasible space for \texttt{simple2} is the left-half region. For the exterior method, these optimizations use the mixed penalty method ($\rho_1=1$, $\rho_2=1$, $\gamma=2$) with gradient descent with Nesterov momentum ($\alpha=1\textsc{E}-3$, $\beta=0.9$) and for the interior method, these optimizations use the log-barrier interior point method ($\rho=1$, $\gamma=2$) on top of the Hooke-Jeeves method ($\alpha_0=1\textsc{E}-1$, $\gamma=0.5$, $\epsilon=1\textsc{E}-4$, $k_{max}=10$). The color gradations for \texttt{simple2} are the base-10 logarithm of the function values.}
    \label{fig:simple1_alg2}
\end{figure*}


% \begin{figure*}
%     \hfill
%     \includesvg[width=0.3\linewidth]{../plots/rosenbrock_conv_3_mult.svg} 
%     \hfill
%     \includesvg[width=0.3\linewidth]{../plots/himmelblau_conv_3_mult.svg} 
%     \hfill
%     \includesvg[width=0.3\linewidth]{../plots/powell_conv_3_mult.svg}
%     \hfill
%     \caption{}
%     \label{fig:conv}
% \end{figure*}


\end{document}